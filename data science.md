**DATA SCIENCE**



What is mean by data science?

            collecting a specified data - (insights) processing information

            Collection of amount of data processing, analyzing it and making insights or predictions

            Statistics are mostly used in data science



1st unit

1st day (Data science)

Theoretical over view-Business problem understanding-KPIs

Data cleaning and wrangling -EDA with pandas- numpy with matplotlib(mathematical plotting library)

sea bond

Hands on experience with e-commerce \[the process of buying and selling goods and services over the internet, involving online transactions, payments, and data transfer Eg. Meesho, Myntra, Ajio, Amazon]



Fintech data type(Financial  technology)



KPI(Key Performance Indicator)  in single word measuring a status

  KPI is a measurable value that shows how well a company, a project, a process is performing

  It is a number whether your process(decision) is success(correct) or not



**Uses of KPI**

make goals measurable

help in finding problem

supports decision making

track the process over time



**Types of KPI**

Quantitative KPI (collection of customer reviews)

Qualitative KPI (customer reviews)

Leading KPI (attracts customer)

Lagging KPI (It stores history of kpi)

Operational KPI ()



**BUSINESS PROBLEM**

    A business problem is a challenge or opportunity a company faces which needs data to understand, solve or improve



**DATA ANALYSIS CHECK**: (mostly depends on sales)

sales drop

sales per product

customer buying pattern (eg. Basically timing for the students to go canteen is common for all the years)

competitor price



**DATA CLEANING**(5 types):- (Data preprocessing steps)

Missing values -> Handling missing values and incorrect values(overcome by statistic methods)

Duplicates

Wrong data type

Inconsistent test

Feature engineering



**FEATURE ENGINEERING**

  (Eg. no of customers visited a day, sales increased because of the product selling place (urban) called features which aims to increase the seasonality of sales)

   Features are give high importance to train our model so that we achieve maximum prediction

    Feature engineering is helps to creating better input features for models from raw data.

        numerical raw data (scaling and binding)

        categorical encoding (separate gender wise)

        Day time features(date-month-year , 3x3 total 9 possibilities )

        aggregated features (units consumed by one family)

        Interaction(one data interacts with other data best eg. BMI calculated by height and weight )



**E-COMMERCE DATA**

grocery products

Fashion \& style (dresses)

Home Decor items

Makeup products (including skincare)

Items in cart

Addresses

Liked products

Location

date

receiver phone number

name of the user

reviews and ratings

price

offers

coupon codes

varieties( includes color, size, brand)

tracking data + api (location tracking)

offers

Mode of payment



**EDA(Exploratory Data Analysis)**

How a data get trend, seasonality, varying and deviation

  From fixed data point how the data get deviated(or) varied is known as deviation







**EDA  Libraries**

EDA with Panda

EDA with numpy

EDA with matplotlib

EDA with seaborn



**DAY-2**



Home made Bakes

 can't appoint people for delivery(in order to reduce more expenses) as they have to take care of their own orders

 Fake orders



Statistic method > Mean, median(centre value), mode(repeated values)



  |                /

  |              /

  |            /

10|           |

8  |      /| |

4  |    /  | |

2  |  /    |/

0  |_____________________







peak value for short period of time(trend)

long period of time(seasonality)



Matplotlib(pictorial representation):

 1.Line plot

 2.Dotplot

 3.Scatter plot

 4.Bar graph



Legends are small square boxes used to denote different varieties(For eg. in  a map where box in the bottom right corner represents land, water and mountains )



IDE (Integrator Development Environment)



**Characteristics**

1. Systematic process involves repeatable framework from problem define to model deployment
2. data-centric requires quality and accuracy based
3. Iterative nature



**STEPS INVOLVED IN MODEL BUILDING**

1. Problem definition -> Explain the problem
2. Data collection -> collecting data required for the solution
3. Pre processing -> cleaning data, handle missing values and address outliers
4. Feature engineering -> create meaningful variables that enhance model prediction
5. Model selection -> Algorithms based on problem type and data characteristics
6. Training -> Fit the model to training data and optimise parameter
7. Evaluation -> Performance using validation sets and relevant metrics
8. Deployment -> Integrate the model into production environments
9. Monitoring -> Model performance and detect degradation over time



[Eg. consider a baby, problem would be help the child to learn things, collecting pics, real apple, 2nd step  clear the damaged one for good learning 3rd one and name it with some variables in our case it would be "APPLE" will be 4th step, 5th step selecting the baby to be learned(trained), next teaching(training) 6th step, testing the baby for memory 7th step, 8th step Allow the baby to wander over environments and finally  check whether the child could find the apple in the environment.]

